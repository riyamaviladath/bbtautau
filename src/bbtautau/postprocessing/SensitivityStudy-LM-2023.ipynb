{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "\n",
    "from boostedhh import utils, hh_vars, plotting\n",
    "from boostedhh.utils import PAD_VAL\n",
    "from bbtautau import bbtautau_vars\n",
    "\n",
    "import SensitivityStudy\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"boostedhh.utils\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "hep.style.use(\"CMS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reloads imported files on edits\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = Path(\"../../../\")\n",
    "CHANNEL = \"electron\"  # options: \"hadronic\", \"electron\", \"muon\"\n",
    "\n",
    "plot_dir = MAIN_DIR / f\"plots/SensitivityStudy/25Mar7{CHANNEL}\"\n",
    "plot_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "years = [\"2022\"]  # [\"2023\",\"2023BPix\"]  # \"2022\",\"2022EE\",\n",
    "\n",
    "tags = {\n",
    "    \"data\": {\n",
    "        \"2022\": \"24Nov21ParTMass_v12_private_signal\",\n",
    "        \"2022EE\": \"25Jan22AddYears_v12_private_signal\",\n",
    "        \"2023\": \"25Mar7Signal_v12_private_signal\",\n",
    "        \"2023BPix\": \"25Mar7Signal_v12_private_signal\",\n",
    "    },\n",
    "    \"signal\": {\n",
    "        \"2022\": \"24Nov21ParTMass_v12_private_signal\",\n",
    "        \"2022EE\": \"25Jan22AddYears_v12_private_signal\",\n",
    "        \"2023\": \"25Mar7Signal_v12_private_signal\",\n",
    "        \"2023BPix\": \"25Mar7Signal_v12_private_signal\",\n",
    "    },\n",
    "}\n",
    "\n",
    "base_dir = {\n",
    "    \"2022\": Path(\"/ceph/cms/store/user/rkansal/bbtautau/skimmer/\"),\n",
    "    \"2022EE\": Path(\"/ceph/cms/store/user/rkansal/bbtautau/skimmer/\"),\n",
    "    \"2023\": Path(\"/ceph/cms/store/user/lumori/bbtautau/skimmer/\"),\n",
    "    \"2023BPix\": Path(\"/ceph/cms/store/user/lumori/bbtautau/skimmer/\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick signal key based on channel\n",
    "SIG_KEYS = {\"hadronic\": \"bbtthh\", \"electron\": \"bbtthe\", \"muon\": \"bbtthmu\"}\n",
    "SIG_KEY = SIG_KEYS[CHANNEL]\n",
    "\n",
    "# pick relevant data samples based on channel\n",
    "DATA_KEYS = {\n",
    "    \"hadronic\": [\"jetmet\", \"tau\"],\n",
    "    \"electron\": [\"jetmet\", \"tau\", \"egamma\"],\n",
    "    \"muon\": [\"jetmet\", \"tau\", \"muon\"],\n",
    "}[CHANNEL]\n",
    "\n",
    "# pick relevant lepton dataset based on channel\n",
    "LEPTON_DATASET = {\"hadronic\": None, \"electron\": \"egamma\", \"muon\": \"muon\"}[CHANNEL]\n",
    "\n",
    "ALL_TRIGGERS = {\n",
    "    \"hadronic\": bbtautau_vars.HLT_hh,\n",
    "    \"muon\": bbtautau_vars.HLT_hmu,\n",
    "    \"electron\": bbtautau_vars.HLT_he,\n",
    "}\n",
    "\n",
    "LEPTON_TRIGGERS = {\n",
    "    \"hadronic\": None,\n",
    "    \"electron\": bbtautau_vars.HLT_he,\n",
    "    \"muon\": bbtautau_vars.HLT_hmu,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SensitivityStudy.Analyser(years, CHANNEL)\n",
    "for year in years:\n",
    "    analyser.extract_year(year)\n",
    "    print(f\"Loaded {year} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcdouts = [\"QCD0HF\", \"QCD1HF\", \"QCD2HF\"]\n",
    "topouts = [\"TopW\", \"TopbW\", \"TopbWev\", \"TopbWmv\", \"TopbWtauhv\", \"TopbWq\", \"TopbWqq\"]\n",
    "sigouts = [\"Xtauhtauh\", \"Xtauhtaue\", \"Xtauhtaum\", \"Xbb\"]\n",
    "\n",
    "columns_data = {\n",
    "    year: [\n",
    "        (\"weight\", 1),\n",
    "        (\"ak8FatJetMsd\", 3),\n",
    "        (\"ak8FatJetEta\", 3),\n",
    "        (\"ak8FatJetPt\", 3),\n",
    "        (\"ak8FatJetPhi\", 3),\n",
    "        (\"ak8FatJetPNetXbbLegacy\", 3),\n",
    "        (\"ak8FatJetPNetQCDLegacy\", 3),\n",
    "        (\"ak8FatJetPNetmassLegacy\", 3),\n",
    "        (\"ak8FatJetParTmassResApplied\", 3),\n",
    "        (\"ak8FatJetParTmassVisApplied\", 3),\n",
    "    ]\n",
    "    for year in years\n",
    "}\n",
    "\n",
    "\n",
    "columns_signal = copy.deepcopy(columns_data)\n",
    "\n",
    "for year in years:\n",
    "    for branch in ALL_TRIGGERS[CHANNEL][year]:\n",
    "        columns_data[year].append((branch, 1))\n",
    "        columns_signal[year].append((branch, 1))\n",
    "\n",
    "    for branch in [f\"ak8FatJetParT{key}\" for key in qcdouts + topouts + sigouts]:\n",
    "        columns_data[year].append((branch, 3))\n",
    "        columns_signal[year].append((branch, 3))\n",
    "\n",
    "    columns_signal[year] += [\n",
    "        (\"GenTauhh\", 1),\n",
    "        (\"GenTauhmu\", 1),\n",
    "        (\"GenTauhe\", 1),\n",
    "        (\"GenHiggsEta\", 2),\n",
    "        (\"GenHiggsPt\", 2),\n",
    "        (\"GenHiggsPhi\", 2),\n",
    "        (\"GenHiggsMass\", 2),\n",
    "        (\"GenbbEta\", 2),\n",
    "        (\"GenbbPt\", 2),\n",
    "        (\"GenbbPhi\", 2),\n",
    "        (\"GenbbMass\", 2),\n",
    "        (\"GenTauEta\", 2),\n",
    "        (\"GenTauPt\", 2),\n",
    "        (\"GenTauPhi\", 2),\n",
    "        (\"GenTauMass\", 2),\n",
    "        (\"single_weight_genweight\", 1),\n",
    "        (\"single_weight_pileup\", 1),\n",
    "        (\"single_weight_ISRPartonShower\", 1),\n",
    "        (\"single_weight_FSRPartonShower\", 1),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define samples to load\n",
    "samples = {\n",
    "    year: {\n",
    "        \"jetmet\": utils.Sample(\n",
    "            path=base_dir[year] / tags[\"data\"][year],\n",
    "            selector=\"JetHT|JetMET\",\n",
    "            label=\"JetMET\",\n",
    "            isData=True,\n",
    "            year=year,\n",
    "            load_columns=utils.format_columns(columns_data[year]),\n",
    "        ),\n",
    "        \"tau\": utils.Sample(\n",
    "            path=base_dir[year] / tags[\"data\"][year],\n",
    "            selector=\"Tau_Run\",\n",
    "            label=\"Tau\",\n",
    "            isData=True,\n",
    "            year=year,\n",
    "            load_columns=utils.format_columns(columns_data[year]),\n",
    "        ),\n",
    "        \"muon\": utils.Sample(\n",
    "            path=base_dir[year] / tags[\"data\"][year],\n",
    "            selector=\"Muon_Run\",\n",
    "            label=\"Muon\",\n",
    "            isData=True,\n",
    "            year=year,\n",
    "            load_columns=utils.format_columns(columns_data[year]),\n",
    "        ),\n",
    "        \"egamma\": utils.Sample(\n",
    "            path=base_dir[year] / tags[\"data\"][year],\n",
    "            selector=\"EGamma_Run\",\n",
    "            label=\"EGamma\",\n",
    "            isData=True,\n",
    "            year=year,\n",
    "            load_columns=utils.format_columns(columns_data[year]),\n",
    "        ),\n",
    "        \"bbtt\": utils.Sample(\n",
    "            path=base_dir[year] / tags[\"signal\"][year],\n",
    "            selector=hh_vars.bbtt_sigs[\"bbtt\"][year],\n",
    "            label=r\"HHbb$\\tau\\tau$\",\n",
    "            isData=False,\n",
    "            year=year,\n",
    "            load_columns=utils.format_columns(columns_signal[year]),\n",
    "        ),\n",
    "    }\n",
    "    for year in years\n",
    "}\n",
    "\n",
    "for key in [\"jetmet\", \"tau\", \"egamma\", \"muon\"]:\n",
    "    if key not in DATA_KEYS:\n",
    "        for year in years:\n",
    "            del samples[year][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt_cut = 250\n",
    "# msd_cut = 40\n",
    "\n",
    "filters = [\n",
    "    [\n",
    "        (\"('ak8FatJetPt', '0')\", \">=\", 250),\n",
    "        (\"('ak8FatJetPNetmassLegacy', '0')\", \">=\", 50),\n",
    "        (\"('ak8FatJetPt', '1')\", \">=\", 200),\n",
    "        # (\"('ak8FatJetMsd', '0')\", \">=\", msd_cut),\n",
    "        # (\"('ak8FatJetMsd', '1')\", \">=\", msd_cut),\n",
    "        # (\"('ak8FatJetPNetXbb', '0')\", \">=\", 0.8),\n",
    "    ],\n",
    "]\n",
    "\n",
    "\n",
    "# dictionary that will contain all information (from all samples)\n",
    "events_dict = {year: {} for year in years}\n",
    "\n",
    "for year in years:\n",
    "    for key, sample in samples[year].items():\n",
    "        events_dict[year][key] = utils.load_sample(sample, filters)\n",
    "\n",
    "    events_dict[year][\"bbtthh\"] = events_dict[year][\"bbtt\"][\n",
    "        events_dict[year][\"bbtt\"][\"GenTauhh\"][0]\n",
    "    ]\n",
    "    events_dict[year][\"bbtthmu\"] = events_dict[year][\"bbtt\"][\n",
    "        events_dict[year][\"bbtt\"][\"GenTauhmu\"][0]\n",
    "    ]\n",
    "    events_dict[year][\"bbtthe\"] = events_dict[year][\"bbtt\"][\n",
    "        events_dict[year][\"bbtt\"][\"GenTauhe\"][0]\n",
    "    ]\n",
    "    del events_dict[year][\"bbtt\"]\n",
    "\n",
    "\n",
    "cutflow = {year: pd.DataFrame(index=list(events_dict[year].keys())) for year in years}\n",
    "\n",
    "for year in years:\n",
    "    utils.add_to_cutflow(events_dict[year], \"Preselection\", \"finalWeight\", cutflow[year])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    print(year)\n",
    "    for skey in SIG_KEYS.values():\n",
    "        print(skey)\n",
    "        triggered = np.sum(\n",
    "            [events_dict[year][skey][hlt].iloc[:, 0] for hlt in ALL_TRIGGERS[CHANNEL][year]],\n",
    "            axis=0,\n",
    "        ).astype(bool)\n",
    "        events_dict[year][skey] = events_dict[year][skey][triggered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data (overlap removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigdict = {year: {\"jetmet\": {}, \"tau\": {}} for year in years}\n",
    "\n",
    "if LEPTON_DATASET:\n",
    "    for year in years:\n",
    "        trigdict[year][LEPTON_DATASET] = {}\n",
    "\n",
    "for year in years:\n",
    "    for key, d in trigdict[year].items():\n",
    "        d[\"all\"] = np.sum(\n",
    "            [events_dict[year][key][hlt].iloc[:, 0] for hlt in ALL_TRIGGERS[CHANNEL][year]], axis=0\n",
    "        ).astype(bool)\n",
    "        d[\"jets\"] = np.sum(\n",
    "            [\n",
    "                events_dict[year][key][hlt].iloc[:, 0]\n",
    "                for hlt in bbtautau_vars.HLT_dict[year][\"PNet\"]\n",
    "                + bbtautau_vars.HLT_dict[year][\"PFJet\"]\n",
    "            ],\n",
    "            axis=0,\n",
    "        ).astype(bool)\n",
    "        d[\"taus\"] = np.sum(\n",
    "            [events_dict[year][key][hlt].iloc[:, 0] for hlt in bbtautau_vars.HLT_taus[year]], axis=0\n",
    "        ).astype(bool)\n",
    "\n",
    "        d[\"taunojets\"] = ~d[\"jets\"] & d[\"taus\"]\n",
    "\n",
    "        if LEPTON_DATASET:\n",
    "            d[LEPTON_DATASET] = np.sum(\n",
    "                [events_dict[year][key][hlt].iloc[:, 0] for hlt in LEPTON_TRIGGERS[CHANNEL][year]],\n",
    "                axis=0,\n",
    "            ).astype(bool)\n",
    "\n",
    "            d[f\"{LEPTON_DATASET}noothers\"] = ~d[\"jets\"] & ~d[\"taus\"] & d[LEPTON_DATASET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking event loss by flipping triggers (can skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xor = np.setdiff1d(\n",
    "#     events_dict[\"jetmet\"][trigdict[\"jetmet\"][\"nojettau\"]][\"event\"][0],\n",
    "#     events_dict[\"tau\"][trigdict[\"tau\"][\"nojettau\"]][\"event\"][0],\n",
    "# )\n",
    "\n",
    "# print(len(xor) / len(events_dict[\"jetmet\"]))\n",
    "\n",
    "# xor = np.setdiff1d(\n",
    "#     events_dict[\"tau\"][trigdict[\"tau\"][\"jetnotau\"]][\"event\"][0],\n",
    "#     events_dict[\"jetmet\"][trigdict[\"jetmet\"][\"jets\"]][\"event\"][0],\n",
    "# )\n",
    "\n",
    "# print(len(xor) / len(events_dict[\"tau\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply overlap removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    events_dict[year][\"jetmet\"] = events_dict[year][\"jetmet\"][trigdict[year][\"jetmet\"][\"jets\"]]\n",
    "    events_dict[year][\"tau\"] = events_dict[year][\"tau\"][trigdict[year][\"tau\"][\"taunojets\"]]\n",
    "    if LEPTON_DATASET:\n",
    "        events_dict[year][LEPTON_DATASET] = events_dict[year][LEPTON_DATASET][\n",
    "            trigdict[year][LEPTON_DATASET][f\"{LEPTON_DATASET}noothers\"]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    utils.add_to_cutflow(events_dict[year], \"Triggers\", \"finalWeight\", cutflow[year])\n",
    "cutflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FatJet Gen Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge years in gen matching\n",
    "events = pd.concat([events_dict[year][SIG_KEY] for year in years], keys=[year for year in years])\n",
    "\n",
    "higgs = utils.make_vector(events, \"GenHiggs\")\n",
    "bb = utils.make_vector(events, \"Genbb\")\n",
    "tt = utils.make_vector(events, \"GenTau\")\n",
    "fatjets = utils.make_vector(events, \"ak8FatJet\", mstring=\"Msd\")\n",
    "\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minbb = np.min(higgs[:, 0:1].deltaR(bb), axis=1)\n",
    "mintau = np.min(higgs[:, 0:1].deltaR(tt), axis=1)\n",
    "genhbb1 = minbb < mintau\n",
    "\n",
    "# minbb = np.min(higgs[:, 1:2].deltaR(bb), axis=1)\n",
    "# mintau = np.min(higgs[:, 1:2].deltaR(tt), axis=1)\n",
    "# genhbb2 = minbb < mintau  # overlap with genhb1 < 0.5% of the time\n",
    "\n",
    "genhbb_mask = np.vstack([genhbb1, ~genhbb1]).T\n",
    "genhbb = higgs[genhbb_mask]\n",
    "genhtt = higgs[~genhbb_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fjbbdr = fatjets.deltaR(genhbb[:, np.newaxis])\n",
    "fjidbb = np.argmin(fjbbdr, axis=1)\n",
    "fjttdr = fatjets.deltaR(genhtt[:, np.newaxis])\n",
    "fjidtt = np.argmin(fjttdr, axis=1)\n",
    "# 5% of events have overlap out of which only 5% actually have two jets both close to a gen Higgs,\n",
    "# so ignoring these overlap events for now\n",
    "overlap = fjidbb == fjidtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggers_dict = {year: {} for year in years}\n",
    "\n",
    "taukey = {\"hadronic\": \"Xtauhtauh\", \"electron\": \"Xtauhtaue\", \"muon\": \"Xtauhtaum\"}[CHANNEL]\n",
    "\n",
    "for year in years:\n",
    "    for key, events in events_dict[year].items():\n",
    "        tvars = {}\n",
    "\n",
    "        qcdouts = [\"QCD0HF\", \"QCD1HF\", \"QCD2HF\"]  # HF = heavy flavor = {c,b}\n",
    "        topouts = [\"TopW\", \"TopbW\"]  # \"TopbWev\", \"TopbWmv\", \"TopbWtauhv\", \"TopbWq\", \"TopbWqq\"]\n",
    "        tvars[\"PQCD\"] = sum([events[f\"ak8FatJetParT{k}\"] for k in qcdouts]).to_numpy()\n",
    "        tvars[\"PTop\"] = sum([events[f\"ak8FatJetParT{k}\"] for k in topouts]).to_numpy()\n",
    "\n",
    "        for disc in [\"Xbb\", taukey]:\n",
    "            tvars[f\"{disc}vsQCD\"] = np.nan_to_num(\n",
    "                events[f\"ak8FatJetParT{disc}\"] / (events[f\"ak8FatJetParT{disc}\"] + tvars[\"PQCD\"]),\n",
    "                nan=PAD_VAL,\n",
    "            )\n",
    "            tvars[f\"{disc}vsQCDTop\"] = np.nan_to_num(\n",
    "                events[f\"ak8FatJetParT{disc}\"]\n",
    "                / (events[f\"ak8FatJetParT{disc}\"] + tvars[\"PQCD\"] + tvars[\"PTop\"]),\n",
    "                nan=PAD_VAL,\n",
    "            )\n",
    "\n",
    "            # make sure not to choose padded jets below by accident\n",
    "            nojet3 = events[\"ak8FatJetPt\"][2] == PAD_VAL\n",
    "            tvars[f\"{disc}vsQCD\"][:, 2][nojet3] = PAD_VAL\n",
    "            tvars[f\"{disc}vsQCDTop\"][:, 2][nojet3] = PAD_VAL\n",
    "\n",
    "        tvars[\"PNetXbbvsQCD\"] = np.nan_to_num(\n",
    "            events[\"ak8FatJetPNetXbbLegacy\"]\n",
    "            / (events[\"ak8FatJetPNetXbbLegacy\"] + events[\"ak8FatJetPNetQCDLegacy\"]),\n",
    "            nan=PAD_VAL,\n",
    "        )\n",
    "\n",
    "        # jet assignment\n",
    "        fjbbpick = np.argmax(tvars[\"XbbvsQCD\"], axis=1)\n",
    "        fjttpick = np.argmax(tvars[f\"{taukey}vsQCD\"], axis=1)\n",
    "        overlap = fjbbpick == fjttpick\n",
    "        fjbbpick[overlap] = np.argsort(tvars[\"XbbvsQCD\"][overlap], axis=1)[:, -2]\n",
    "\n",
    "        # convert ids to boolean masks\n",
    "        fjbbpick_mask = np.zeros_like(tvars[\"XbbvsQCD\"], dtype=bool)\n",
    "        fjbbpick_mask[np.arange(len(fjbbpick)), fjbbpick] = True\n",
    "        fjttpick_mask = np.zeros_like(tvars[f\"{taukey}vsQCD\"], dtype=bool)\n",
    "        fjttpick_mask[np.arange(len(fjttpick)), fjttpick] = True\n",
    "\n",
    "        tvars[\"bb_mask\"] = fjbbpick_mask\n",
    "        tvars[\"tautau_mask\"] = fjttpick_mask\n",
    "        taggers_dict[year][key] = tvars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking bb matching accuracy (can skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = {}\n",
    "if len(years) > 1:\n",
    "    for key in taggers_dict[years[0]][SIG_KEY].keys():\n",
    "        tvars[key] = np.concatenate([taggers_dict[year][SIG_KEY][key] for year in years])\n",
    "else:\n",
    "    tvars = taggers_dict[years[0]][SIG_KEY]\n",
    "\n",
    "maxtxbb = np.max(tvars[\"XbbvsQCD\"], axis=1)\n",
    "fjbbpick = np.argmax(tvars[\"XbbvsQCD\"], axis=1)\n",
    "maxtxtt = np.max(tvars[f\"{taukey}vsQCD\"], axis=1)\n",
    "fjttpick = np.argmax(tvars[f\"{taukey}vsQCD\"], axis=1)\n",
    "\n",
    "# how many are assigned correctly?\n",
    "print(f\"Correct matching bb: {np.mean(fjbbpick == fjidbb)}\")\n",
    "print(f\"Correct matching tt: {np.mean(fjttpick == fjidtt)}\")\n",
    "\n",
    "overlap = fjbbpick == fjttpick\n",
    "print(f\"Overlap: {np.mean(overlap)}\")\n",
    "# how many pass reasonable tagger cuts?\n",
    "print(\n",
    "    f\"How many overlaps pass basic tagger cuts: {np.sum((maxtxbb > 0.8) * (maxtxtt > 0.95) * overlap) / np.sum(overlap)}\"\n",
    ")  # <0.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jet_vals(vals, mask):\n",
    "    # check if vals is a numpy array\n",
    "    if not isinstance(vals, np.ndarray):\n",
    "        vals = vals.to_numpy()\n",
    "\n",
    "    return vals[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "def compute_rocs(\n",
    "    years,\n",
    "    jets=[\"bb\", \"tautau\"],\n",
    "    discs=[\"XbbvsQCD\", \"XbbvsQCDTop\", f\"{taukey}vsQCD\", f\"{taukey}vsQCDTop\", \"PNetXbbvsQCD\"],\n",
    "):\n",
    "\n",
    "    rocs = {}\n",
    "\n",
    "    for jet in jets:\n",
    "        print(jet)\n",
    "        rocs[jet] = {}\n",
    "        for i, disc in enumerate(discs):\n",
    "            print(\"\\t\" + disc)\n",
    "\n",
    "            bg_scores = np.concatenate(\n",
    "                [\n",
    "                    get_jet_vals(\n",
    "                        taggers_dict[year][key][disc], taggers_dict[year][key][f\"{jet}_mask\"]\n",
    "                    )\n",
    "                    for key in DATA_KEYS\n",
    "                    for year in years\n",
    "                ]\n",
    "            )\n",
    "            bg_weights = np.concatenate(\n",
    "                [events_dict[year][key][\"finalWeight\"] for key in DATA_KEYS for year in years]\n",
    "            )\n",
    "\n",
    "            sig_scores = np.concatenate(\n",
    "                [\n",
    "                    get_jet_vals(\n",
    "                        taggers_dict[year][SIG_KEY][disc],\n",
    "                        taggers_dict[year][SIG_KEY][f\"{jet}_mask\"],\n",
    "                    )\n",
    "                    for year in years\n",
    "                ]\n",
    "            )\n",
    "            sig_weights = np.concatenate(\n",
    "                [events_dict[year][SIG_KEY][\"finalWeight\"] for year in years]\n",
    "            )\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(\n",
    "                np.concatenate([np.zeros_like(bg_scores), np.ones_like(sig_scores)]),\n",
    "                np.concatenate([bg_scores, sig_scores]),\n",
    "                sample_weight=np.concatenate([bg_weights, sig_weights]),\n",
    "            )\n",
    "\n",
    "            rocs[jet][disc] = {\n",
    "                \"fpr\": fpr,\n",
    "                \"tpr\": tpr,\n",
    "                \"thresholds\": thresholds,\n",
    "                \"label\": disc,\n",
    "                \"color\": plt.cm.tab10.colors[i],\n",
    "            }\n",
    "\n",
    "    return rocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocs_full = compute_rocs(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jet, title in zip([\"bb\", \"tautau\"], [\"bb FatJet\", rf\"$\\tau_h\\tau_{CHANNEL[0]}$ FatJet\"]):\n",
    "    if len(years) > 1:\n",
    "        for i, year in enumerate(years):\n",
    "            if i == 0:\n",
    "                title += f\" {year}\"\n",
    "            else:\n",
    "                title += f\"+{year}\"\n",
    "    else:\n",
    "        title = title + f\" {years[0]}\"\n",
    "\n",
    "    plotting.multiROCCurveGrey(\n",
    "        {\"\": rocs_full[jet]},\n",
    "        title=title,\n",
    "        show=True,\n",
    "        plot_dir=plot_dir,\n",
    "        name=f\"roc_{jet} {years}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocs = {year: compute_rocs([year]) for year in years}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for jet, title in zip([\"bb\", \"tautau\"], [\"bb FatJet\", rf\"$\\tau_h\\tau_{CHANNEL[0]}$ FatJet\"]):\n",
    "        plotting.multiROCCurveGrey(\n",
    "            {\"\": rocs[year][jet]},\n",
    "            title=title + \" \" + year,\n",
    "            show=True,\n",
    "            plot_dir=plot_dir,\n",
    "            name=f\"roc_{jet} {year}\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for key, label in zip([\"hhbbtt\", \"data\"], [\"HHbbtt\", \"Data\"]):\n",
    "        if key == \"hhbbtt\":\n",
    "            events = events_dict[year][SIG_KEY]\n",
    "        else:\n",
    "            events = pd.concat([events_dict[year][dkey] for dkey in DATA_KEYS])\n",
    "\n",
    "        bins = np.linspace(0, 250, 50)\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(24, 10))\n",
    "\n",
    "        for i, (jet, jlabel) in enumerate(\n",
    "            zip([\"bb\", \"tautau\"], [\"bb FatJet\", r\"$\\tau\\tau$ FatJet\"])\n",
    "        ):\n",
    "            ax = axs[i]\n",
    "            if key == \"hhbbtt\":\n",
    "                mask = taggers_dict[year][SIG_KEY][f\"{jet}_mask\"]\n",
    "            else:\n",
    "                mask = np.concatenate(\n",
    "                    [taggers_dict[year][dkey][f\"{jet}_mask\"] for dkey in DATA_KEYS], axis=0\n",
    "                )\n",
    "\n",
    "            for j, (mkey, mlabel) in enumerate(\n",
    "                zip(\n",
    "                    [\n",
    "                        \"ak8FatJetMsd\",\n",
    "                        \"ak8FatJetPNetmassLegacy\",\n",
    "                        \"ak8FatJetParTmassResApplied\",\n",
    "                        \"ak8FatJetParTmassVisApplied\",\n",
    "                    ],\n",
    "                    [\"SoftDrop\", \"PNetLegacy\", \"ParT Res\", \"ParT Vis\"],\n",
    "                )\n",
    "            ):\n",
    "                ax.hist(\n",
    "                    get_jet_vals(events[mkey], mask),\n",
    "                    bins=bins,\n",
    "                    histtype=\"step\",\n",
    "                    weights=events[\"finalWeight\"],\n",
    "                    label=mlabel,\n",
    "                    linewidth=2,\n",
    "                    color=plt.cm.tab10.colors[j],\n",
    "                )\n",
    "\n",
    "            ax.vlines(125, 0, ax.get_ylim()[1], linestyle=\"--\", color=\"k\", alpha=0.1)\n",
    "            ax.set_title(jlabel, fontsize=24)\n",
    "            ax.set_xlabel(\"Mass [GeV]\")\n",
    "            # rax.set_xlabel(\"Mass [GeV]\")\n",
    "            ax.set_ylabel(\"Events\")\n",
    "            ax.legend()\n",
    "            ax.set_ylim(0)\n",
    "            hep.cms.label(\n",
    "                ax=ax,\n",
    "                data=key == \"data\",\n",
    "                year=year,\n",
    "                com=\"13.6\",\n",
    "                fontsize=20,\n",
    "                lumi=f\"{hh_vars.LUMI[year] / 1000:.1f}\",\n",
    "            )\n",
    "\n",
    "        plt.savefig(plot_dir / f\"{key}_{year}_mass.pdf\", bbox_inches=\"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cut-and-count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# bbeff, tteff = 0.44,0.36 #0.44, 0.36 values determined by highest sig for 1 bkg event\n",
    "mbb1, mbb2 = 110.0, 160.0\n",
    "mbbw2 = (mbb2 - mbb1) / 2\n",
    "mtt1, mtt2 = 50, 1500\n",
    "\n",
    "# mbbk = \"PNetmassLegacy\"\n",
    "mbbk = \"ParTmassResApplied\"\n",
    "# mttk = \"PNetmassLegacy\"\n",
    "mttk = \"ParTmassResApplied\"\n",
    "\n",
    "txbbs = {year: {} for year in years}\n",
    "txtts = {year: {} for year in years}\n",
    "masstt = {year: {} for year in years}\n",
    "massbb = {year: {} for year in years}\n",
    "ptbb = {year: {} for year in years}\n",
    "\n",
    "# precompute to speedup\n",
    "for year in years:\n",
    "    for key in [SIG_KEY] + DATA_KEYS:\n",
    "        txbbs[year][key] = get_jet_vals(\n",
    "            taggers_dict[year][key][\"XbbvsQCD\"], taggers_dict[year][key][\"bb_mask\"]\n",
    "        )\n",
    "        txtts[year][key] = get_jet_vals(\n",
    "            taggers_dict[year][key][f\"{taukey}vsQCDTop\"], taggers_dict[year][key][\"tautau_mask\"]\n",
    "        )\n",
    "        masstt[year][key] = get_jet_vals(\n",
    "            events_dict[year][key][f\"ak8FatJet{mttk}\"], taggers_dict[year][key][\"tautau_mask\"]\n",
    "        )\n",
    "        massbb[year][key] = get_jet_vals(\n",
    "            events_dict[year][key][f\"ak8FatJet{mbbk}\"], taggers_dict[year][key][\"bb_mask\"]\n",
    "        )\n",
    "        ptbb[year][key] = get_jet_vals(\n",
    "            events_dict[year][key][\"ak8FatJetPt\"], taggers_dict[year][key][\"bb_mask\"]\n",
    "        )\n",
    "\n",
    "\n",
    "def compute_sig_bg(year, txbbcut, txttcut, mbb1, mbb2, mbbw2, mtt1, mtt2):\n",
    "    bg_yield = 0\n",
    "    sig_yield = 0\n",
    "\n",
    "    for key in [SIG_KEY] + DATA_KEYS:\n",
    "        # plt.hist(massbb, np.linspace(0, 200, 100), histtype=\"step\", label=key, weights=events_dict[key][\"finalWeight\"])\n",
    "        if key == SIG_KEY:\n",
    "            cut = (\n",
    "                (txbbs[year][key] > txbbcut)\n",
    "                & (txtts[year][key] > txttcut)\n",
    "                & (masstt[year][key] > mtt1)\n",
    "                & (masstt[year][key] < mtt2)\n",
    "                & (massbb[year][key] > mbb1)\n",
    "                & (massbb[year][key] < mbb2)\n",
    "                & (ptbb[year][key] > 250)\n",
    "            )\n",
    "            sig_yield += np.sum(events_dict[year][key][\"finalWeight\"][cut])\n",
    "        else:\n",
    "            cut = (\n",
    "                (txbbs[year][key] > txbbcut)\n",
    "                & (txtts[year][key] > txttcut)\n",
    "                & (masstt[year][key] > mtt1)\n",
    "                & (masstt[year][key] < mtt2)\n",
    "                & (ptbb[year][key] > 250)\n",
    "            )\n",
    "            msb1 = (massbb[year][key] > (mbb1 - mbbw2)) & (massbb[year][key] < mbb1)\n",
    "            msb2 = (massbb[year][key] > mbb2) & (massbb[year][key] < (mbb2 + mbbw2))\n",
    "            bg_yield += np.sum(events_dict[year][key][\"finalWeight\"][cut & msb1])\n",
    "            bg_yield += np.sum(events_dict[year][key][\"finalWeight\"][cut & msb2])\n",
    "    return sig_yield, bg_yield\n",
    "\n",
    "\n",
    "def sig_bkg_opt(year, gridsize=100, gridlims=(0.5, 1), plot=False):\n",
    "    # bbeff_vals = np.linspace(0.3, 0.7, gridsize)\n",
    "    # tteff_vals = np.linspace(0.3, 0.7, gridsize)\n",
    "    bbcut = np.linspace(*gridlims, gridsize)\n",
    "    ttcut = np.linspace(*gridlims, gridsize)\n",
    "\n",
    "    BBcut, TTcut = np.meshgrid(bbcut, ttcut)\n",
    "\n",
    "    # scalar function, must be vectorized\n",
    "    sig_bg = lambda bbcut, ttcut: compute_sig_bg(\n",
    "        year=year,\n",
    "        txbbcut=bbcut,\n",
    "        txttcut=ttcut,\n",
    "        # txbbcut=rocs[year][\"bb\"][\"XbbvsQCD\"][\"thresholds\"][\n",
    "        #     plotting._find_nearest(rocs[years[0]][\"bb\"][\"XbbvsQCD\"][\"tpr\"], bbeff)\n",
    "        # ],\n",
    "        # txttcut=rocs[year][\"tautau\"][f\"{taukey}vsQCDTop\"][\"thresholds\"][\n",
    "        #     plotting._find_nearest(rocs[years[0]][\"tautau\"][f\"{taukey}vsQCDTop\"][\"tpr\"], tteff)\n",
    "        # ],\n",
    "        mbb1=mbb1,\n",
    "        mbb2=mbb2,\n",
    "        mbbw2=mbbw2,\n",
    "        mtt1=mtt1,\n",
    "        mtt2=mtt2,\n",
    "    )\n",
    "\n",
    "    sigs, bgs = np.vectorize(sig_bg)(BBcut, TTcut)\n",
    "    sel = bgs == 1\n",
    "\n",
    "    if np.sum(sel) == 0:\n",
    "        n = 2\n",
    "        while np.sum(sel) == 0:\n",
    "            sel = (bgs >= 1) & (bgs <= n)\n",
    "            n += 1\n",
    "        print(f\"Need a finer grid, no region with B=1. I'm extending the region to B in [1,{n}].\")\n",
    "\n",
    "    sel_idcs = np.argwhere(sel)\n",
    "    sel_sigs = sigs[sel]\n",
    "\n",
    "    opt_i = np.argmax(sel_sigs)\n",
    "    max_sig_idx = tuple(sel_idcs[opt_i])\n",
    "    bbcut_opt, ttcut_opt = BBcut[max_sig_idx], TTcut[max_sig_idx]\n",
    "\n",
    "    print(bgs)\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        hep.cms.label(\n",
    "            ax=ax,\n",
    "            data=True,\n",
    "            year=year,\n",
    "            com=\"13.6\",\n",
    "            fontsize=16,\n",
    "            lumi=f\"{hh_vars.LUMI[year] / 1000:.1f}\",\n",
    "        )\n",
    "        sigmap = ax.contourf(BBcut, TTcut, sigs, levels=10, cmap=\"viridis\")\n",
    "        contour = ax.contour(BBcut, TTcut, sel, colors=\"r\")\n",
    "        proxy = Line2D([0], [0], color=\"r\", label=\"B=1 level\")\n",
    "        ax.scatter(bbcut_opt, ttcut_opt, color=\"r\", label=\"Optimal cut\")\n",
    "        ax.set_xlabel(\"Xbb vs QCD cut\")\n",
    "        ax.set_ylabel(\"Xtauhtauh vs QCD cut\")\n",
    "        cbar = plt.colorbar(sigmap, ax=ax)\n",
    "        cbar.set_label(\"Signal yield\")\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        handles.append(proxy)\n",
    "        ax.legend(handles=handles, loc=\"lower left\")\n",
    "        plt.savefig(plot_dir / f\"sig_bkg_opt_{year}.pdf\", bbox_inches=\"tight\")\n",
    "        plt.savefig(plot_dir / f\"sig_bkg_opt_{year}.png\", bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "    return sigs[max_sig_idx], bgs[max_sig_idx], [bbcut_opt, ttcut_opt]\n",
    "\n",
    "\n",
    "def print_nicely(sig_yield, bg_yield, years):\n",
    "    print(\n",
    "        f\"\"\"\n",
    "        \n",
    "        Yield study year(s) {years}:\n",
    "        \n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    print(\"Sig yield\", sig_yield)\n",
    "    print(\"BG yield\", bg_yield)\n",
    "    print(\"limit\", 2 * np.sqrt(bg_yield) / sig_yield)\n",
    "\n",
    "    if \"2023\" not in years or \"2023BPix\" not in years:\n",
    "        print(\n",
    "            \"limit scaled to 22-23 all channels\",\n",
    "            2\n",
    "            * np.sqrt(bg_yield)\n",
    "            / sig_yield\n",
    "            / np.sqrt(\n",
    "                hh_vars.LUMI[\"2022-2023\"] / np.sum([hh_vars.LUMI[year] for year in years]) * 3\n",
    "            ),\n",
    "        )\n",
    "    print(\n",
    "        \"limit scaled to 22-24 all channels\",\n",
    "        2\n",
    "        * np.sqrt(bg_yield)\n",
    "        / sig_yield\n",
    "        / np.sqrt(\n",
    "            (124000 + hh_vars.LUMI[\"2022-2023\"])\n",
    "            / np.sum([hh_vars.LUMI[year] for year in years])\n",
    "            * 3\n",
    "        ),\n",
    "    )\n",
    "    print(\n",
    "        \"limit scaled to Run 3 all channels\",\n",
    "        2 * np.sqrt(bg_yield) / sig_yield / np.sqrt((360000) / hh_vars.LUMI[year] * 3),\n",
    "    )\n",
    "    return\n",
    "\n",
    "\n",
    "def as_df(sig_yield, bg_yield, years):\n",
    "    limits = {}\n",
    "\n",
    "    limits[\"Sig_Yield\"] = sig_yield\n",
    "    limits[\"BG_Yield\"] = bg_yield\n",
    "    limits[\"Limit\"] = 2 * np.sqrt(bg_yield) / sig_yield\n",
    "\n",
    "    if \"2023\" not in years and \"2023BPix\" not in years:\n",
    "        limits[\"Limit_scaled_22_23\"] = (\n",
    "            2\n",
    "            * np.sqrt(bg_yield)\n",
    "            / sig_yield\n",
    "            / np.sqrt(\n",
    "                hh_vars.LUMI[\"2022-2023\"] / np.sum([hh_vars.LUMI[year] for year in years]) * 3\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        limits[\"Limit_scaled_22_23\"] = np.nan\n",
    "\n",
    "    limits[\"Limit_scaled_22_24\"] = (\n",
    "        2\n",
    "        * np.sqrt(bg_yield)\n",
    "        / sig_yield\n",
    "        / np.sqrt(\n",
    "            (124000 + hh_vars.LUMI[\"2022-2023\"])\n",
    "            / np.sum([hh_vars.LUMI[year] for year in years])\n",
    "            * 3\n",
    "        )\n",
    "    )\n",
    "\n",
    "    limits[\"Limit_scaled_Run3\"] = (\n",
    "        2\n",
    "        * np.sqrt(bg_yield)\n",
    "        / sig_yield\n",
    "        / np.sqrt((360000) / np.sum([hh_vars.LUMI[year] for year in years]) * 3)\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame([limits])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig, bkg, [bbcut, ttcut] = sig_bkg_opt(\"2023BPix\", gridsize=3, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcdefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocs[\"2023BPix\"][\"tautau\"][f\"{taukey}vsQCDTop\"][\"thresholds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_combined = 0\n",
    "sig_combined = 0\n",
    "\n",
    "results = {}\n",
    "\n",
    "for year in years:\n",
    "    sig_yield, bkg_yield, [bbcut, ttcut] = sig_bkg_opt(year, gridsize=30, plot=True)\n",
    "    results[year] = as_df(sig_yield, bkg_yield, [year])\n",
    "    bg_combined += bkg_yield\n",
    "    sig_combined += sig_yield\n",
    "\n",
    "results[\"Combined\"] = as_df(sig_combined, bg_combined, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat(results, axis=0)\n",
    "results_df.index = results_df.index.droplevel(1)\n",
    "print(results_df.T.to_markdown())\n",
    "results_df.T.to_csv(plot_dir / f\"{years}-results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Muons                   |        2023 |    2023BPix |    Combined |\n",
    "|:-------------------|------------:|------------:|------------:|\n",
    "| Sig_Yield          |   0.0305736 |   0.0150834 |   0.0456569 |\n",
    "| BG_Yield           |   1         |   0         |   1         |\n",
    "| Limit              |  65.416     |   0         |  43.805     |\n",
    "| Limit_scaled_22_23 | nan         | nan         | nan         |\n",
    "| Limit_scaled_22_24 |  11.6528    |   0         |   9.66919   |\n",
    "| Limit_scaled_Run3  |   8.36266   |   0         |   6.93912   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Period (Electrons)**                        | **2022**  | **2022EE** | **Combined (2022, 2022EE)** |\n",
    "|-------------------------------------|----------:|----------:|---------------------------:|\n",
    "| **Sig yield**                       | 0.015     | 0.046     | 0.061                     |\n",
    "| **BG yield**                        | 2.000     | 7.000     | 9.000                     |\n",
    "| **limit**                           | 190.635   | 115.250   | 98.765                    |\n",
    "| **limit scaled to 22-23 channels**  | 39.654    | 43.576    | 42.621                    |\n",
    "| **limit scaled to 22-24 channels**  | 22.821    | 25.078    | 24.529                    |\n",
    "| **limit scaled to Run 3 channels**  | 16.378    | 17.997    | 17.603                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Period (Muons)**                        | **2022**  | **2022EE** | **Combined (2022, 2022EE)** |\n",
    "|-------------------------------------|---------:|----------:|---------------------------:|\n",
    "| **Sig yield**                       | 0.015    | 0.047     | 0.062                     |\n",
    "| **BG yield**                        | 0.000    | 3.000     | 3.000                     |\n",
    "| **limit**                           | 0.000    | 73.528    | 55.506                    |\n",
    "| **limit scaled to 22-23 channels**  | 0.000    | 27.801    | 23.953                    |\n",
    "| **limit scaled to 22-24 channels**  | 0.000    | 16.000    | 13.785                    |\n",
    "| **limit scaled to Run 3 channels**  | 0.000    | 11.482    | 9.893                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Period (Full hadronic)**                        | **2022**  | **2022EE** | **Combined (2022, 2022EE)** |\n",
    "|-------------------------------------|---------:|----------:|---------------------------:|\n",
    "| **Sig yield**                       | 0.032    | 0.104     | 0.136                     |\n",
    "| **BG yield**                        | 1.000    | 3.000     | 4.000                     |\n",
    "| **limit**                           | 62.243   | 33.457    | 29.483                    |\n",
    "| **limit scaled to 22-23 channels**  | 12.947   | 12.650    | 12.723                    |\n",
    "| **limit scaled to 22-24 channels**  | 7.451    | 7.280     | 7.322                     |\n",
    "| **limit scaled to Run 3 channels**  | 5.347    | 5.225     | 5.255                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
